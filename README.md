# Unified Northlight Platform

> **Integrated Data Pipeline and Business Intelligence Platform**
> Combining Heartbeat's ETL capabilities with Northlight's benchmarking and analytics

## ğŸ¯ Overview

The Unified Northlight Platform consolidates two previously separate systems:
- **Heartbeat**: Sophisticated ETL pipeline for extracting data from corporate portals, Salesforce, and Ultimate DMS
- **Northlight**: Benchmarking and campaign performance analysis web application

This unified platform provides a single source of truth for all business data with real-time analytics, automated reporting, and comprehensive data management.

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Data Sources  â”‚    â”‚  ETL Pipeline    â”‚    â”‚  PostgreSQL DB  â”‚
â”‚                 â”‚â”€â”€â”€â–¶â”‚                  â”‚â”€â”€â”€â–¶â”‚                 â”‚
â”‚ â€¢ Corp Portal   â”‚    â”‚ â€¢ Extract        â”‚    â”‚ â€¢ Campaign Data â”‚
â”‚ â€¢ Salesforce    â”‚    â”‚ â€¢ Transform      â”‚    â”‚ â€¢ Benchmarks    â”‚
â”‚ â€¢ Ultimate DMS  â”‚    â”‚ â€¢ Load           â”‚    â”‚ â€¢ Analytics     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                        â”‚
                                                        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Frontend UI   â”‚    â”‚   FastAPI App    â”‚    â”‚  Business Logic â”‚
â”‚                 â”‚â—€â”€â”€â”€â”‚                  â”‚â—€â”€â”€â”€â”‚                 â”‚
â”‚ â€¢ Dashboards    â”‚    â”‚ â€¢ REST APIs      â”‚    â”‚ â€¢ Benchmarking  â”‚
â”‚ â€¢ Reports       â”‚    â”‚ â€¢ Authentication â”‚    â”‚ â€¢ Analytics     â”‚
â”‚ â€¢ Analytics     â”‚    â”‚ â€¢ WebSockets     â”‚    â”‚ â€¢ Reporting     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸš€ Quick Start

### Prerequisites

- Python 3.9+
- PostgreSQL 15+
- Redis 7+ (for caching)
- Docker & Docker Compose (recommended)

### Installation

1. **Clone and Setup**
   ```bash
   cd unified-northlight
   python -m venv venv
   source venv/bin/activate  # On Windows: venv\Scripts\activate
   pip install -r requirements.txt
   ```

2. **Database Setup**
   ```bash
   # Start PostgreSQL and Redis with Docker
   docker-compose up -d

   # Initialize database schema
   python scripts/init_database.py
   ```

3. **Configure Environment**
   ```bash
   # Copy and edit environment file
   cp .env.example .env
   # Edit .env with your credentials and settings
   ```

4. **Run Application**
   ```bash
   python main.py
   ```

   The application will be available at:
   - **API Documentation**: http://localhost:8000/docs
   - **Dashboard**: http://localhost:8000/dashboard
   - **Health Check**: http://localhost:8000/health

## ğŸ“ Project Structure

```
unified-northlight/
â”œâ”€â”€ ğŸ“„ main.py                     # FastAPI application entry point
â”œâ”€â”€ ğŸ“„ requirements.txt            # Python dependencies
â”œâ”€â”€ ğŸ“„ .env                        # Environment configuration
â”œâ”€â”€ ğŸ“„ docker-compose.yml          # Container orchestration
â”‚
â”œâ”€â”€ ğŸ“ api/                        # REST API endpoints
â”‚   â””â”€â”€ ğŸ“ v1/                     # API version 1
â”‚       â”œâ”€â”€ benchmarking.py        # Benchmarking endpoints
â”‚       â”œâ”€â”€ etl_management.py      # ETL control endpoints
â”‚       â””â”€â”€ reporting.py           # Report generation endpoints
â”‚
â”œâ”€â”€ ğŸ“ core/                       # Core platform modules
â”‚   â”œâ”€â”€ config.py                  # Configuration management
â”‚   â”œâ”€â”€ database.py                # Database connections
â”‚   â””â”€â”€ shared.py                  # Shared utilities
â”‚
â”œâ”€â”€ ğŸ“ etl/                        # ETL pipeline (from Heartbeat)
â”‚   â”œâ”€â”€ ğŸ“ heartbeat/              # Preserved Heartbeat ETL modules
â”‚   â”œâ”€â”€ ğŸ“ extractors/             # Data extraction modules
â”‚   â”œâ”€â”€ ğŸ“ transformers/           # Data transformation modules
â”‚   â””â”€â”€ ğŸ“ loaders/                # Data loading modules
â”‚
â”œâ”€â”€ ğŸ“ frontend/                   # Web interface (from Northlight)
â”‚   â”œâ”€â”€ index.html                 # Main dashboard
â”‚   â”œâ”€â”€ static/                    # CSS, JS, images
â”‚   â””â”€â”€ components/                # UI components
â”‚
â”œâ”€â”€ ğŸ“ database/                   # Database management
â”‚   â”œâ”€â”€ ğŸ“ init/                   # Schema initialization scripts
â”‚   â””â”€â”€ ğŸ“ migrations/             # Database migrations
â”‚
â”œâ”€â”€ ğŸ“ scripts/                    # Utility and deployment scripts
â”‚   â”œâ”€â”€ init_database.py           # Database setup
â”‚   â”œâ”€â”€ migrate_data.py            # Data migration utilities
â”‚   â””â”€â”€ deploy.py                  # Deployment automation
â”‚
â””â”€â”€ ğŸ“ data/                       # Data storage
    â”œâ”€â”€ ğŸ“ raw/                    # Raw extracted data
    â”œâ”€â”€ ğŸ“ processed/              # Transformed data
    â””â”€â”€ ğŸ“ exports/                # Generated reports
```

## ğŸ”§ Configuration

Key environment variables:

```bash
# Database
DATABASE_URL=postgresql://app_user:password@localhost:5432/unified_northlight

# Corporate Portal
CORP_PORTAL_USERNAME=your.email@company.com
CORP_PORTAL_PASSWORD=your_password

# Salesforce
SF_USERNAME=your.email@company.com
SF_PASSWORD=your_password

# Application
API_HOST=0.0.0.0
API_PORT=8000
DEBUG=true
```

## ğŸ“Š Features

### ETL Pipeline
- **Automated Data Extraction** from multiple sources
- **Intelligent Data Transformation** with validation
- **Real-time Loading** into PostgreSQL
- **Comprehensive Monitoring** and alerting
- **Error Recovery** and retry mechanisms

### Benchmarking & Analytics
- **Campaign Performance Analysis** with industry benchmarks
- **Interactive Dashboards** for KPI monitoring
- **Automated Report Generation** (PDF, PowerPoint, Excel)
- **Real-time Data Updates** and notifications
- **Advanced Filtering** and data exploration

### API & Integration
- **RESTful APIs** for all platform functions
- **WebSocket Support** for real-time updates
- **OpenAPI Documentation** with Swagger UI
- **Rate Limiting** and authentication
- **Webhook Support** for external integrations

## ğŸ› ï¸ Development

### Running Tests
```bash
pytest tests/ -v --cov=.
```

### Code Quality
```bash
# Format code
black .
isort .

# Lint code
flake8 .
mypy .
```

### Database Migrations
```bash
# Create migration
alembic revision --autogenerate -m "Description"

# Apply migrations
alembic upgrade head
```

## ğŸ“ˆ Monitoring

- **Health Checks**: `/health` endpoint for application status
- **Metrics**: Prometheus metrics on `/metrics`
- **Logs**: Structured logging with rotation
- **Alerts**: Slack/email notifications for issues

## ğŸ”’ Security

- **Environment-based Configuration** (no secrets in code)
- **Database Connection Pooling** with proper cleanup
- **CORS Protection** with configurable origins
- **Input Validation** and sanitization
- **Rate Limiting** on API endpoints

## ğŸ“ Migration Guide

### From Legacy Systems

1. **Data Migration**: Run `python scripts/migrate_data.py` to transfer existing data
2. **Configuration**: Update legacy scripts to use new database connections
3. **Testing**: Validate all functionality with `python scripts/validate_migration.py`

### Breaking Changes

- Database changed from DuckDB to PostgreSQL
- API endpoints consolidated under `/api/v1/`
- Configuration format updated (see `.env.example`)

## ğŸ¤ Contributing

1. Create feature branch: `git checkout -b feature/your-feature`
2. Make changes with tests
3. Ensure code quality: `make lint test`
4. Submit pull request

## ğŸ“‹ Roadmap

- [ ] **Phase 1**: Core platform integration *(Current)*
- [ ] **Phase 2**: Advanced analytics and ML features
- [ ] **Phase 3**: Multi-tenant support
- [ ] **Phase 4**: Mobile application
- [ ] **Phase 5**: Third-party integrations

## ğŸ“ Support

- **Documentation**: Available in `/docs/`
- **Issues**: GitHub Issues for bug reports
- **Questions**: Contact the development team

---

**Built with â¤ï¸ by the Unified Northlight Team**